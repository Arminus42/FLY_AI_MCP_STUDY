import asyncio
import sys
import time
import ast  # ë¬¸ìì—´ë¡œ ëœ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±ìš©
from typing import Optional
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from openai import OpenAI, RateLimitError
from dotenv import load_dotenv

from openai.types.chat import (
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
    ChatCompletionMessageToolCallParam,
    ChatCompletionToolMessageParam,
    ChatCompletionToolParam,
)
from openai.types.chat.chat_completion_message_tool_call_param import Function
from openai.types.shared_params.function_definition import FunctionDefinition

import json
import argparse
import traceback

load_dotenv()

class MCPClient:
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.llm = OpenAI()
        self.messages = []
        # íŒŒì¼ í•˜ë‚˜ë‹¹ ìµœëŒ€ í„´ ìˆ˜ (ì¶©ë¶„í•¨)
        self.max_retries = 30 

    async def connect_to_server(self, server_script_path: str):
        server_params = StdioServerParameters(
            command=sys.executable,
            args=[server_script_path],
            env=None
        )
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()
        
        response = await self.session.list_tools()
        print(f"\n[ì‹œìŠ¤í…œ] ì„œë²„ ì—°ê²° ì„±ê³µ. ë„êµ¬ ëª©ë¡: {[tool.name for tool in response.tools]}")

    async def cleanup(self):
        try:
            await self.exit_stack.aclose()
        except Exception:
            pass

    async def process_messages(self, messages: list[ChatCompletionMessageParam]):
        if len(messages) > self.max_retries:
            print("[ì‹œìŠ¤í…œ] í•´ë‹¹ íŒŒì¼ì— ëŒ€í•œ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            return messages

        response = await self.session.list_tools()
        available_tools = [ChatCompletionToolParam(
            type="function",
            function=FunctionDefinition(
                name=tool.name,
                description=tool.description if tool.description else "",
                parameters=tool.inputSchema
            )
        ) for tool in response.tools]

        # ---------------------------------------------------------
        # [í•µì‹¬] Rate Limit (429) ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„ ë¡œì§ (Exponential Backoff)
        # ---------------------------------------------------------
        max_api_retries = 5
        for attempt in range(max_api_retries):
            try:
                response_llm = self.llm.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    tools=available_tools,
                    tool_choice="auto"
                )
                break # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
            except RateLimitError as e:
                wait_time = (2 ** attempt) + 1  # 2ì´ˆ, 3ì´ˆ, 5ì´ˆ... ëŠ˜ë ¤ê°
                print(f"\n[ê²½ê³ ] OpenAI Rate Limit ë„ë‹¬! {wait_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... ({attempt+1}/{max_api_retries})")
                time.sleep(wait_time)
            except Exception as e:
                print(f"\n[ì˜¤ë¥˜] API í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
                raise e
        else:
            print("[ì˜¤ë¥˜] ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ë¡œ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return messages
        # ---------------------------------------------------------

        finish_reason = response_llm.choices[0].finish_reason
        assistant_message = response_llm.choices[0].message

        if finish_reason == "stop": 
            # LLMì´ í•  ë§ì„ ë§ˆì¹˜ë©´ ì¶œë ¥í•˜ê³  ì¢…ë£Œ (ë‹¤ìŒ ë‹¨ê³„ë¡œ)
            print(f"\n[AI ì‘ë‹µ]: {assistant_message.content}")
            messages.append(
                ChatCompletionAssistantMessageParam(
                    role="assistant",
                    content=assistant_message.content
                )
            )

        elif finish_reason == "tool_calls":
            tool_calls = assistant_message.tool_calls
            assert tool_calls is not None
            
            messages.append(
                ChatCompletionAssistantMessageParam(
                    role="assistant",
                    tool_calls=[
                        ChatCompletionMessageToolCallParam(
                            id=tc.id,
                            function=Function(arguments=tc.function.arguments, name=tc.function.name),
                            type=tc.type,
                        ) for tc in tool_calls
                    ]
                )
            )

            for tool_call in tool_calls:
                print(f"[ë„êµ¬ í˜¸ì¶œ] {tool_call.function.name}({tool_call.function.arguments})")

            # ë„êµ¬ ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬)
            tasks = [asyncio.create_task(self.process_tool_call(tc)) for tc in tool_calls]
            tool_results = await asyncio.gather(*tasks)
            messages.extend(tool_results)
            
            # ì¬ê·€ í˜¸ì¶œ
            return await self.process_messages(messages)

        return messages

    async def process_tool_call(self, tool_call) -> ChatCompletionToolMessageParam:
        tool_name = tool_call.function.name
        tool_args = json.loads(tool_call.function.arguments)
        
        try:
            call_tool_result = await self.session.call_tool(tool_name, tool_args)
            if call_tool_result.isError:
                content = f"ì˜¤ë¥˜ ë°œìƒ: {call_tool_result.content}"
            else:
                content = call_tool_result.content[0].text
        except Exception as e:
            content = f"ë„êµ¬ ì‹¤í–‰ ì˜ˆì™¸: {str(e)}"

        preview = content[:150] + "..." if len(content) > 150 else content
        print(f"[ë„êµ¬ ê²°ê³¼] {preview}")

        return ChatCompletionToolMessageParam(
            role="tool",
            content=content,
            tool_call_id=tool_call.id
        )

    async def workflow_loop(self, prompt: str):
        print("\n[ì‹œìŠ¤í…œ] ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤. ëŒ€ìƒ ëª¨ë“ˆ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤...")

        # 1. Python ë ˆë²¨ì—ì„œ ì§ì ‘ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸ í™•ë³´
        list_result = await self.session.call_tool("list_target_modules", {})
        modules_str = list_result.content[0].text
        
        try:
            # ë¬¸ìì—´ "['example1', 'example2']"ë¥¼ ì‹¤ì œ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            target_modules = ast.literal_eval(modules_str)
            print(f"[ì‹œìŠ¤í…œ] ë°œê²¬ëœ ëª¨ë“ˆ: {target_modules}")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return

        # 2. ê° ëª¨ë“ˆë³„ë¡œ 'ë…ë¦½ëœ' ëŒ€í™” ì„¸ì…˜ ì‹œì‘ (Context Reset)
        for module_name in target_modules:
            print(f"\n{'='*50}")
            print(f"ğŸš€ [Start] ëª¨ë“ˆ ì²˜ë¦¬ ì‹œì‘: {module_name}")
            print(f"{'='*50}")

            # [ì¤‘ìš”] ë©”ì‹œì§€ ê¸°ë¡ ì´ˆê¸°í™”! (ì´ì „ íŒŒì¼ì˜ ê¸°ì–µì„ ì§€ì›Œ í† í° ì ˆì•½)
            self.messages = [] 
            
            # [ìš”ì²­í•˜ì‹  Surgical QA í”„ë¡¬í”„íŠ¸ ì ìš©]
            system_instruction = f"""
You are a Surgical Python QA Engineer. Your goal is to achieve 100% statement coverage for the '{module_name}' module.

[STRATEGY - FOLLOW STRICTLY]
1. **CRASHES FIRST**: If the test fails to run (ImportError, SyntaxError), fix these errors immediately.
2. **ASSERTION FAILURES**: If an `assert` fails, **TRUST THE SOURCE CODE**. Update your test expectation.
3. **MISSING LINES**: Only add tests for lines specified in the coverage report as "Missing".
4. **NO HALLUCINATIONS**: Do not copy source code or invent functions.

[WORKFLOW]
1. **Analyze**: Read the source code using the tool.
2. **Draft**: Create `test_{module_name}.py` (Handle edge cases).
3. **Save**: Save the test file.
4. **Verify**: Run pytest and measure coverage.
5. **Refine (Loop)**:
   - If coverage < 100%, analyze "Missing lines" and modify the test.
   - Save and Run again.
   - **LIMIT**: Repeat refinement maximum 3 times.
6. **Finalize**: 
   - Call `mark_as_best_submission` with the current result.

[MANDATORY FINAL STEP]
**EVEN IF COVERAGE IS NOT 100%, YOU MUST CALL `mark_as_best_submission` BEFORE EXITING.**
Do not end the conversation without saving your best attempt.
"""
            self.messages.append({"role": "user", "content": system_instruction})

            try:
                # íŒŒì¼ í•˜ë‚˜ë‹¹ íƒ€ì„ì•„ì›ƒ 3ë¶„ (ì¶©ë¶„í•¨)
                await asyncio.wait_for(self.process_messages(self.messages), timeout=180)
            except asyncio.TimeoutError:
                print(f"[ì‹œìŠ¤í…œ] {module_name} ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼! ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            except Exception as e:
                print(f"[ì‹œìŠ¤í…œ] {module_name} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
                traceback.print_exc()
            
            # API Rate Limit íšŒë³µì„ ìœ„í•´ íŒŒì¼ ê°„ 2ì´ˆ íœ´ì‹
            time.sleep(2)

        print("\n[ì‹œìŠ¤í…œ] ëª¨ë“  ëª¨ë“ˆ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

async def main(server_script_path: str, prompt: str):
    client = MCPClient()
    try:
        await client.connect_to_server(server_script_path)
        await client.workflow_loop(prompt)
    finally:
        await client.cleanup()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('server_script_path', help="Path to server script")
    parser.add_argument('prompt', nargs='?', help="Prompt", default="")
    args = parser.parse_args()

    asyncio.run(main(args.server_script_path, args.prompt))